{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b269bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\roseh\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94593e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\roseh\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96c91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/00/09/abb305dce85911b8fba382926cfc57f2f257729e25937fdcc63f3a1a67f9/wordcloud-1.9.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.4-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from wordcloud) (2.1.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\roseh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/299.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 20.5/299.9 kB 330.3 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 30.7/299.9 kB 262.6 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 61.4/299.9 kB 363.1 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/299.9 kB 554.9 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/299.9 kB 697.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.9 kB 827.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 299.9/299.9 kB 842.1 kB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23fe570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c947a534",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:25\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     IS64,\n\u001b[0;32m     19\u001b[0m     PY39,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     PYPY,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     is_numpy_dev,\n\u001b[0;32m     27\u001b[0m     np_version_under1p21,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     33\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_function_name\u001b[39m(f: F, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m F:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Appender,\n\u001b[0;32m      4\u001b[0m     Substitution,\n\u001b[0;32m      5\u001b[0m     cache_readonly,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     hash_array,\n\u001b[0;32m     10\u001b[0m     hash_pandas_object,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[0;32m      8\u001b[0m     Callable,\n\u001b[0;32m      9\u001b[0m     Mapping,\n\u001b[0;32m     10\u001b[0m     cast,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     F,\n\u001b[0;32m     17\u001b[0m     T,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     NaT,\n\u001b[0;32m     16\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     iNaT,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Assurez-vous d'avoir téléchargé les ressources nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Charger le modèle SpaCy en français\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "# Définir les données sous forme de DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Question': [\n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir', \n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir', \n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir', \n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir',\n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir',\n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir',\n",
    "        'Vision pour l\\'avenir', 'Vision pour l\\'avenir', 'Vision pour l\\'avenir',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Succès de l\\'équipe',\n",
    "        'Succès de l\\'équipe', 'Succès de l\\'équipe', 'Suggestions', 'Suggestions', \n",
    "        'Suggestions', 'Suggestions', 'Suggestions', 'Suggestions', 'Suggestions',\n",
    "        'Suggestions', 'Suggestions', 'Suggestions', 'Suggestions', 'Suggestions', \n",
    "        'Suggestions'\n",
    "    ],\n",
    "    'Réponse': [\n",
    "        \"Atteindre un niveau industriel en vue des exportations.\",\n",
    "        \"Chercher une meilleure façon de relancer le projet\",\n",
    "        \"Devenir un grand leader dans la valorisation du Afitin, un condiment emblématique du Bénin\",\n",
    "        \"Devenir une entreprise entièrement stable et apportant des solutions innovantes.\",\n",
    "        \"Devenir une entreprise s'impose dans le secteur de fournitures de matériels de plantation végétaux.\",\n",
    "        \"Élargir les produits à l'échelle internationale\",\n",
    "        \"Étendre notre champ d'action, être l'une des meilleures entreprises de notre domaine.\",\n",
    "        \"Être l'une des plus grandes unités de production de charbon écologique dans la sous région\",\n",
    "        \"Être une référence à Adjohoun\",\n",
    "        \"Faire marcher l'entreprise\",\n",
    "        \"Installer une sine dynamique de production des aliments à base de l'igname.\",\n",
    "        \"Je ne fais plus partie du groupe\",\n",
    "        \"L'agrandir convenablement\",\n",
    "        \"L'espoir de renaître de l'impact douloureux, pesant et persistant de l'échec passé...\",\n",
    "        \"Mettre le produit sur le marché, faire la commercialisation et atteindre toutes les couches de la société.\",\n",
    "        \"Notre vision est de pouvoir offrir une marque de Afitin africaine...\",\n",
    "        \"Notre vision est d'être des fournisseurs de farine sans gluten d'ici 2 ans\",\n",
    "        \"Notre vision est d'être une entreprise modernisée dans la production des détergents et reconnu à l'international.\",\n",
    "        \"Notre vision est devenir d'ici 2030 une entreprise de référence dans la production écologique des légumes...\",\n",
    "        \"Notre vision est d'impacter positivement la population par nos services et de devenir investisseurs dans le domaine de l'énergie\",\n",
    "        \"Nous faire connaître en diversifiant notre marché sur le plan national qu'international\",\n",
    "        \"Nous souhaitons devenir les leaders nationaux et sous-régionaux dans la production et la commercialisation de Akpan.\",\n",
    "        \"Nous visons exporter notre purée de noix de palme dans toute la sous-région.\",\n",
    "        \"Obtenir l'autorisation de mise sur le marché\",\n",
    "        \"Plus grande entreprise de vente d'épices locale\",\n",
    "        \"Projet abandonné\",\n",
    "        \"Redynamiser le projet pour éclore les potentialités dudit projet et de la Team Directrice\",\n",
    "        \"Reprendre à Zéro avec de nouvelles idées\",\n",
    "        \"Rester focus sur les produits les plus vendus\",\n",
    "        \"Toucher d'autres régions du pays avec notre service et l'Afrique\",\n",
    "        \"Transformer numériquement la pisciculture au Bénin...\",\n",
    "        \"Transformer numériquement la pisciculture et la pêche en un vivier d'opportunités au Bénin.\",\n",
    "        \"L'échelle de production a augmenté, nos produits sont désormais dans les rayons de supermarché\",\n",
    "        \"Réalisation des différents produits- succès des ventes des produits sur les marchés...\",\n",
    "        \"2ème prix Salon de l'entrepreneuriat 2024, 2ème prix Bénin Research Health forum\",\n",
    "        \"Acquisition des infrastructures et équipements indispensables à la production.\",\n",
    "        \"Au début nous avions réussi l'organisation à l'interne puisque nous espérons un financement\",\n",
    "        \"Comme principaux succès, nous pouvons citer la concrétisation des projets...\",\n",
    "        \"Coopération et dynamisme\",\n",
    "        \"Essais de prototype, obtention des subventions, expérience de gestion\",\n",
    "        \"Formalisation, Sécurisation d'un site de production stratégique\",\n",
    "        \"Il n'a pas eu de succès en tant que tel. L'équipe n'est plus fonctionnelle...\",\n",
    "        \"Il n'y a en réalité pas de succès à proprement parler\",\n",
    "        \"J'ai juste recours à un Centre de Gestion Agréée\",\n",
    "        \"La disponibilité et l’efficacité du produit qui est déjà sur le marché.\",\n",
    "        \"La mise sur le marché d'un produit innovant (cuiseur éco). Obtention de plusieurs prix\",\n",
    "        \"La réception du fonds SEF de la MasterCard, l'acquisition de certains équipements...\",\n",
    "        \"L'acquisition du matériel et la réalisation du prototype...\",\n",
    "        \"Le maintien de l'engagement au quotidien\",\n",
    "        \"Le prototypage réussi\",\n",
    "        \"L'entreprise continue de fonctionner\",\n",
    "        \"Lors des cotisations, tous les membres n'étaient pas en mesure de donner leur parts.\",\n",
    "        \"Nos principales succès : démarrage de la production sur 1/4 ha...\",\n",
    "        \"Notre entreprise a su être résiliente...\",\n",
    "        \"Nous avons atteint la majorité de nos objectifs\",\n",
    "        \"Nous n'avons pas encore réalisé de succès observable.\",\n",
    "        \"Nous n'avons pas encore réalisé de succès observables à ce jour\",\n",
    "        \"Nous nous sommes installés avec l'équipement nécessaire pour la production...\",\n",
    "        \"Produits sur le marché\",\n",
    "        \"Prototype disponible et vendu\",\n",
    "        \"Prototype réussi, fond de roulement disponible pour le lancement officiel du projet.\",\n",
    "        \"RAS\",\n",
    "        \"Réalisation du prototype du produit et mise sur le marché\",\n",
    "        \"Réussite d'obtention de financement\",\n",
    "        \"Tout le monde s'impliquait dans lancement des activités au début\",\n",
    "        \"très difficile à dire, on gère à travers les moyens disponibles\",\n",
    "        \"Un leader disponible pour conduire les activités d'installation...\",\n",
    "        \"Total général\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Nettoyer les textes et les tokeniser\n",
    "def nettoyer_texte(texte):\n",
    "    # Mise en minuscule et suppression de la ponctuation\n",
    "    texte = texte.lower()\n",
    "    texte = ''.join([char for char in texte if char.isalnum() or char.isspace()])\n",
    "    return texte\n",
    "\n",
    "data['Réponse_Nettoyée'] = data['Réponse'].apply(nettoyer_texte)\n",
    "\n",
    "# Fonction de tokenisation et suppression des mots vides\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "def nettoyer_tokens(texte):\n",
    "    tokens = word_tokenize(texte)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Tokenisation des réponses\n",
    "data['Tokens'] = data['Réponse_Nettoyée'].apply(nettoyer_tokens)\n",
    "\n",
    "# Analyse des mots fréquents\n",
    "all_tokens = [token for sublist in data['Tokens'] for token in sublist]\n",
    "frequence_mots = Counter(all_tokens)\n",
    "\n",
    "# Affichage des 10 mots les plus fréquents\n",
    "print(frequence_mots.most_common(10))\n",
    "\n",
    "# Générer un nuage de mots\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(frequence_mots)\n",
    "\n",
    "# Affichage du nuage de mots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Analyse des entités avec spaCy\n",
    "def analyser_entites(texte):\n",
    "    doc = nlp(texte)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Extraire les entités de chaque réponse\n",
    "data['Entites'] = data['Réponse_Nettoyée'].apply(analyser_entites)\n",
    "\n",
    "# Afficher les entités détectées\n",
    "print(data[['Réponse', 'Entites']].head())\n",
    "\n",
    "# Analyse des mots-clés pour des thèmes spécifiques : Leadership, Cohésion, Prise de décision\n",
    "keywords_leadership = ['leadership', 'leader', 'diriger', 'commandant']\n",
    "keywords_cohesion = ['cohésion', 'collaboration', 'esprit d\\'équipe', 'solidarité']\n",
    "keywords_prise_decision = ['décision', 'choix', 'plan', 'stratégie']\n",
    "\n",
    "def count_keywords(texte, keywords):\n",
    "    count = sum([1 for word in word_tokenize(texte.lower()) if word in keywords])\n",
    "    return count\n",
    "\n",
    "data['Leadership'] = data['Réponse_Nettoyée'].apply(count_keywords, keywords=keywords_leadership)\n",
    "data['Cohesion'] = data['Réponse_Nettoyée'].apply(count_keywords, keywords=keywords_cohesion)\n",
    "data['Prise_Decision'] = data['Réponse_Nettoyée'].apply(count_keywords, keywords=keywords_prise_decision)\n",
    "\n",
    "# Résumer les résultats pour chaque thème\n",
    "print(data[['Réponse', 'Leadership', 'Cohesion', 'Prise_Decision']].head())\n",
    "\n",
    "# Visualisation des résultats des thèmes analysés\n",
    "themes = ['Leadership', 'Cohesion', 'Prise_Decision']\n",
    "data[themes].sum().plot(kind='bar', color=['blue', 'green', 'orange'])\n",
    "plt.title('Fréquence des thèmes dans les réponses')\n",
    "plt.ylabel('Nombre d\\'occurrences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc7a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403404d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
